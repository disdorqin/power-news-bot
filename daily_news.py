import requests
import datetime
import os

# --- ç¯å¢ƒå˜é‡ ---
XP_TOKEN = os.environ.get("XP_TOKEN")
XP_UID = os.environ.get("XP_UID")

KEYWORDS = ["electricity forecasting", "load forecasting", "time series forecasting"]

def get_github_updates():
    print("æ­£åœ¨æœç´¢ GitHub...")
    results = []
    date_str = (datetime.datetime.now() - datetime.timedelta(days=1)).strftime('%Y-%m-%d')
    for keyword in KEYWORDS:
        url = f"https://api.github.com/search/repositories?q={keyword}+pushed:>{date_str}&sort=updated&order=desc"
        try:
            response = requests.get(url).json()
            if "items" in response:
                for item in response["items"][:3]:
                    repo_name = item['full_name']
                    repo_url = item['html_url']
                    desc = item['description']
                    stars = item['stargazers_count']
                    # HTML æ ¼å¼ä¼˜åŒ–
                    results.append(f"ğŸ“¦ <b>{repo_name}</b> (â­{stars})<br>ğŸ”— <a href='{repo_url}'>{repo_url}</a><br>ğŸ“ {desc}<br>")
        except Exception as e:
            print(f"GitHub Error: {e}")
    return results

def get_arxiv_updates():
    print("æ­£åœ¨æœç´¢ ArXiv...")
    results = []
    import urllib.request as libreq
    import xml.etree.ElementTree as ET
    for keyword in KEYWORDS:
        query = keyword.replace(" ", "+")
        url = f'http://export.arxiv.org/api/query?search_query=all:{query}&start=0&max_results=3&sortBy=submittedDate&sortOrder=descending'
        try:
            with libreq.urlopen(url) as url_file:
                response = url_file.read()
            root = ET.fromstring(response)
            ns = {'atom': 'http://www.w3.org/2005/Atom'}
            for entry in root.findall('atom:entry', ns):
                title = entry.find('atom:title', ns).text.replace('\n', ' ')
                link = entry.find('atom:id', ns).text
                published = entry.find('atom:published', ns).text[:10]
                results.append(f"ğŸ“„ <b>{title}</b><br>ğŸ“… {published}<br>ğŸ”— <a href='{link}'>{link}</a><br>")
        except Exception as e:
            print(f"ArXiv Error: {e}")
    return list(set(results))

def send_wxpusher(content):
    if not XP_TOKEN or not XP_UID:
        print("âŒ æœªé…ç½® WxPusher å¯†é’¥ï¼Œè·³è¿‡å‘é€")
        return

    url = "https://wxpusher.zjiecode.com/api/send/message"
    
    # æ„é€ è¯·æ±‚æ•°æ®
    data = {
        "appToken": XP_TOKEN,
        "content": content,
        "summary": f"âš¡ ç”µåŠ›æ—¥æŠ¥ ({datetime.datetime.now().strftime('%m-%d')})", # æ¶ˆæ¯æ‘˜è¦
        "contentType": 2, # 2è¡¨ç¤ºHTML
        "uids": [XP_UID],
        "verifyPay": False
    }
    
    try:
        res = requests.post(url, json=data).json()
        if res['code'] == 1000:
            print("âœ… å¾®ä¿¡æ¨é€æˆåŠŸï¼")
        else:
            print(f"âŒ æ¨é€å¤±è´¥: {res['msg']}")
    except Exception as e:
        print(f"âŒ ç½‘ç»œé”™è¯¯: {e}")

if __name__ == "__main__":
    github_data = get_github_updates()
    arxiv_data = get_arxiv_updates()
    
    html_msg = "<h2>ğŸš€ ä»Šæ—¥ GitHub æ›´æ–°</h2>" + ("<br>".join(github_data) if github_data else "æš‚æ— æ–°é¡¹ç›®")
    html_msg += "<br><hr><h2>ğŸ“š æœ€æ–° ArXiv è®ºæ–‡</h2>" + ("<br>".join(arxiv_data) if arxiv_data else "æš‚æ— æ–°è®ºæ–‡")
    
    send_wxpusher(html_msg)
